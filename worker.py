# -*- coding: utf-8 -*-
"""
åå°ç®¡é“ï¼šä»…ä¿ç•™æœ€æ–°å¸§/æœ€æ–°ç»“æœï¼ˆå•æ§½è¦†ç›–ï¼‰ï¼ŒOCR ä¸ LLM åœ¨çº¿ç¨‹æ± æ‰§è¡Œï¼›
LLM ä½¿ç”¨ Future.result(timeout) ä¸ç†”æ–­ï¼Œå¤±è´¥é™çº§è¿”å›åŸæ–‡ï¼Œä¸»çº¿ç¨‹æ°¸ä¸é˜»å¡ã€‚
"""
from __future__ import annotations

import threading
import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError
from typing import Optional

import config
from agents.agent_e import LLMCache, LLMThrottler
from agents.debounce import OCRDebouncer
from agents.llm_correct import correct_with_llm
from tools.logger_util import log_result
from tools.ocr_engine import run_ocr
from shared_state import SharedState
from agents.tts_agent import speak as tts_speak, speak_immediate as tts_speak_immediate, generate_tts_file


class _CircuitBreaker:
    """ç†”æ–­ï¼šè¿ç»­å¤±è´¥ N æ¬¡åï¼Œåœ¨ cooldown ç§’å†…ä¸å†è°ƒç”¨ LLMï¼Œç›´æ¥é™çº§è¿”å›åŸæ–‡ã€‚"""

    def __init__(
        self,
        failure_threshold: int,
        cooldown_sec: float,
    ):
        self._lock = threading.Lock()
        self._failure_threshold = failure_threshold
        self._cooldown_sec = cooldown_sec
        self._consecutive_failures = 0
        self._last_failure_time: float = 0.0

    def record_success(self) -> None:
        with self._lock:
            self._consecutive_failures = 0

    def record_failure(self) -> None:
        with self._lock:
            self._consecutive_failures += 1
            self._last_failure_time = time.monotonic()

    def is_open(self) -> bool:
        with self._lock:
            if self._consecutive_failures < self._failure_threshold:
                return False
            return (time.monotonic() - self._last_failure_time) < self._cooldown_sec


def _run_ocr_safe(frame) -> "tuple[str, float, float, bool, str | None]":
    """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ OCRï¼Œè¿”å› (raw_text, confidence, time_ms, success, error_msg)ã€‚"""
    r = run_ocr(frame)
    return (r.text, r.confidence, r.time_ms, r.success, r.error_msg)


def _run_llm_safe(raw_text: str) -> "tuple[str, float, bool, str | None]":
    """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ LLMï¼Œè¿”å› (corrected_text, time_ms, success, error_msg)ã€‚"""
    r = correct_with_llm(raw_text)
    return (r.corrected_text, r.time_ms, r.success, r.error_msg)


def _run_vision_and_cross_validate(state: SharedState, corrected_text: str) -> None:
    """ç”¨å½“å‰ç¼“å­˜çš„å¸§è·‘è§†è§‰ LLMï¼Œä¸ corrected åšäº¤å‰éªŒè¯å¹¶å†™å…¥ stateã€‚"""
    if not getattr(config, "ENABLE_VISION_LLM", False):
        return
    frame = state.get_and_clear_last_ocr_frame()
    if frame is None:
        return
    try:
        from agents.vision_llm_agent import extract_text_from_image, merge_ocr_and_vision_with_llm
        vision_text = extract_text_from_image(frame)
        mode = getattr(config, "CROSS_VALIDATE_MODE", "show_both")
        if mode == "prefer_ocr":
            cross = corrected_text.strip()
        elif mode == "prefer_vision":
            cross = vision_text
        elif mode == "merge_llm":
            cross = merge_ocr_and_vision_with_llm(corrected_text.strip(), vision_text)
        else:
            cross = corrected_text.strip()  # show_both æ—¶äº¤å‰ç»“æœä»ä»¥ OCR ä¸ºä¸»ï¼Œvision å•ç‹¬æ˜¾ç¤º
        state.set_vision_and_cross_validated(vision_text, cross)
    except Exception:
        pass


def _pipeline_loop(
    state: SharedState,
    executor: ThreadPoolExecutor,
    circuit_breaker: _CircuitBreaker,
    debouncer: OCRDebouncer,
    metrics: Optional["Metrics"] = None,
    cache: Optional[LLMCache] = None,
    throttler: Optional[LLMThrottler] = None,
) -> None:
    """ç®¡é“å¾ªç¯ï¼šåªå–æœ€æ–°å¸§ï¼ˆå•æ§½ï¼‰ï¼ŒOCR â†’ å»æŠ–åŠ¨ â†’ LLMï¼ˆç¼“å­˜+èŠ‚æµ+ç†”æ–­ï¼‰ï¼Œå†™å›æœ€æ–°ç»“æœï¼›å¹¶å¤„ç†ç”¨æˆ·æŒ‡ä»¤ï¼ˆR/T/P/Eï¼‰ã€‚"""
    from tools.logger_util import log, save_debug_frame
    last_llm_lang_hint: Optional[str] = None
    last_sent_text: Optional[str] = None
    last_corrected: Optional[str] = None
    # LLM å¼‚æ­¥ï¼šä¸é˜»å¡ç®¡é“ï¼Œæäº¤åç«‹å³ç»§ç»­åš OCRï¼Œç»“æœåœ¨ä¸‹ä¸€è½®åˆå¹¶
    pending_llm: Optional[tuple] = None  # (future, stable_text, conf, ocr_ms, display_raw, err_msg)

    while True:
        # ç”¨æˆ·æŒ‡ä»¤ Agentï¼šè¯»/ç¿»è¯‘/è¯»éŸ³/ä¾‹å¥ï¼ˆä¸»çº¿ç¨‹å·² set_pending_user_commandï¼‰ï¼Œæ”¾å…¥çº¿ç¨‹æ‰§è¡Œé¿å…é˜»å¡ OCR
        cmd, content = state.get_and_clear_pending_command()
        if cmd:
            def _run_user_command():
                if cmd == "read":
                    # æœ—è¯»æ”¹ä¸ºç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¹¶å†™å…¥å¯¹è¯ï¼Œç”±å¯¹è¯æ¡†å†…ã€ŒğŸ”Š æ’­æ”¾ã€ç‚¹å‡»æ’­æ”¾ï¼Œä¸è°ƒç”¨ç³»ç»Ÿæ’­æ”¾å™¨
                    try:
                        path = generate_tts_file(content or "")
                        if path:
                            state.append_chat("assistant", "æ­£åœ¨æœ—è¯»ã€‚", audio_path=path)
                        else:
                            state.append_chat("assistant", "ï¼ˆæœ—è¯»ç”Ÿæˆå¤±è´¥æˆ–æš‚æ— æ–‡å­—ï¼‰")
                    except Exception:
                        state.append_chat("assistant", "ï¼ˆæœ—è¯»ç”Ÿæˆå¤±è´¥ï¼‰")
                elif content:
                    from agents.user_command_agents import (
                        translate_with_llm,
                        pronunciation_with_llm,
                        examples_with_llm,
                    )
                    if cmd == "translate":
                        result = translate_with_llm(content)
                        state.set_explanation("ç¿»è¯‘", result)
                        state.append_chat("assistant", "ã€ç¿»è¯‘ã€‘\n" + (result or "ï¼ˆæ— ç»“æœï¼‰"))
                    elif cmd == "pronounce":
                        result = pronunciation_with_llm(content)
                        state.set_explanation("è¯»éŸ³", result)
                        state.append_chat("assistant", "ã€è¯»éŸ³ã€‘\n" + (result or "ï¼ˆæ— ç»“æœï¼‰"))
                    elif cmd == "examples":
                        result = examples_with_llm(content)
                        state.set_explanation("ä¾‹å¥", result)
                        state.append_chat("assistant", "ã€ä¾‹å¥ã€‘\n" + (result or "ï¼ˆæ— ç»“æœï¼‰"))
            threading.Thread(target=_run_user_command, daemon=True).start()

        # è¯­éŸ³åŠ©æ‰‹ Agentï¼šç”¨æˆ·æ¶ˆæ¯å·²ç”± main æ˜¾ç¤ºï¼›æ­¤å¤„åªåšâ€œæ­£åœ¨ç†è§£â€æç¤ºå¹¶åœ¨çº¿ç¨‹ä¸­è°ƒ LLMï¼Œä¸é˜»å¡ OCR
        if getattr(config, "ENABLE_VOICE_ASSISTANT", False):
            pending_chat = state.get_and_clear_pending_chat()
            if pending_chat:
                msg = (pending_chat or "").strip()
                content, confidence = state.get_content_and_confidence_for_command()
                keywords = getattr(config, "VOICE_READ_COMMAND_KEYWORDS", ("è¯»ä¸€ä¸‹", "è¯»å‡ºæ¥", "æœ—è¯»", "è¯»ä¸€ä¸‹è§†é¢‘"))
                conf_thresh = getattr(config, "VOICE_READ_DIRECT_CONFIDENCE", 0.0)
                is_read_cmd = any(k in msg for k in keywords)
                # ã€Œè¯»ä¸€ä¸‹ã€ä¸”æœ‰ç”»é¢æ–‡å­—æ—¶ä¼˜å…ˆç›´æ¥æœ—è¯»ï¼Œä¸èµ° LLMï¼Œä¿è¯é¡ºåºæ­£ç¡®ä¸”ç«‹åˆ»æœ‰éŸ³é¢‘
                if is_read_cmd and content and (confidence >= conf_thresh if conf_thresh > 0 else True):
                    try:
                        # è¯­è¨€æ£€æµ‹ä¼˜å…ˆç”¨ debounced_ocrï¼ˆå¯èƒ½ä¿ç•™é‡éŸ³ï¼‰ï¼Œé¿å…çº é”™åä¸¢é‡éŸ³è¢«è¯»æˆè‹±è¯­
                        content_for_lang = state.get_content_for_tts_lang_detect()
                        path = generate_tts_file(content, lang_detect_text=content_for_lang or None)
                        if path:
                            _content_preview = (content[:600] + "â€¦") if len(content) > 600 else content
                            state.set_last_read_content(content)
                            state.append_chat("assistant", "æ­£åœ¨æœ—è¯»ã€‚\nã€å†…å®¹ã€‘\n" + _content_preview, audio_path=path)
                        else:
                            state.append_chat("assistant", "ï¼ˆæœ—è¯»ç”Ÿæˆå¤±è´¥æˆ–æš‚æ— æ–‡å­—ï¼‰")
                    except Exception:
                        state.append_chat("assistant", "ï¼ˆæœ—è¯»ç”Ÿæˆå¤±è´¥ï¼‰")
                else:
                    history = state.get_chat_history()
                    last_user_idx = None
                    for i in range(len(history) - 1, -1, -1):
                        if history[i][0] == "user":
                            last_user_idx = i
                            break
                    raw = (
                        history[:last_user_idx]
                        if last_user_idx is not None
                        else (history[:-1] if history else [])
                    )
                    recent = [(h[0], h[1]) for h in raw] if raw else []
                    content = state.get_content_for_command()

                    if getattr(config, "VOICE_ASSISTANT_DIRECT_LLM", False):
                        # ç›´æ¥å¯¹æ¥ LLMï¼šæµå¼ï¼ˆVOICE_ASSISTANT_USE_STREAM=Trueï¼‰è¾¹æ”¶è¾¹æ˜¾ç¤ºï¼›å¦åˆ™ä¸€æ¬¡æ€§è¯·æ±‚
                        state.start_streaming()
                        use_stream = getattr(config, "VOICE_ASSISTANT_USE_STREAM", True)
                        def _run_direct_llm():
                            try:
                                if use_stream:
                                    from agents.voice_assistant_agent import chat_direct_llm_stream
                                    reply = chat_direct_llm_stream(
                                        pending_chat,
                                        recent if recent else None,
                                        content,
                                        on_chunk=state.append_streaming_delta,
                                    )
                                else:
                                    from agents.voice_assistant_agent import chat_direct_llm
                                    reply = chat_direct_llm(pending_chat, recent if recent else None, content)
                                state.finish_streaming(reply)
                            except Exception as e:
                                state.finish_streaming(f"(åŠ©æ‰‹å‡ºé”™: {str(e)[:50]})")
                        threading.Thread(target=_run_direct_llm, daemon=True).start()
                    else:
                        # åŸæœ‰é€»è¾‘ï¼šæ„å›¾è§£æ + [ACTION:xxx]
                        state.append_chat("assistant", "æ­£åœ¨ç†è§£å¹¶æ‰§è¡Œâ€¦")
                        def _run_chat_assistant():
                            try:
                                from agents.voice_assistant_agent import chat_with_assistant
                                reply, action = chat_with_assistant(pending_chat, recent if recent else None)
                                if action == "read":
                                    content_for_cmd = state.get_content_for_command()
                                    content_for_lang = state.get_content_for_tts_lang_detect()
                                    path = generate_tts_file(content_for_cmd or "", lang_detect_text=content_for_lang or None)
                                    if path:
                                        _txt = (content_for_cmd or "")[:600]
                                        if len(content_for_cmd or "") > 600:
                                            _txt += "â€¦"
                                        state.set_last_read_content(content_for_cmd or "")
                                        state.append_chat("assistant", "æ­£åœ¨æœ—è¯»ã€‚\nã€å†…å®¹ã€‘\n" + _txt, audio_path=path)
                                    else:
                                        state.append_chat("assistant", reply or "ï¼ˆæœ—è¯»ç”Ÿæˆå¤±è´¥ï¼‰")
                                else:
                                    state.append_chat("assistant", reply)
                                    if action == "translate_previous":
                                        content_prev = state.get_last_read_content()
                                        if content_prev:
                                            from agents.user_command_agents import translate_with_llm
                                            result = translate_with_llm(content_prev)
                                            state.append_chat("assistant", "ã€ç¿»è¯‘ã€‘ï¼ˆä¸Šä¸€å¥ï¼‰\n" + (result or "ï¼ˆæ— ç»“æœï¼‰"))
                                        else:
                                            state.append_chat("assistant", "ï¼ˆæ²¡æœ‰ä¹‹å‰çš„æœ—è¯»å†…å®¹å¯ç¿»è¯‘ï¼Œè¯·å…ˆã€Œè¯»ä¸€ä¸‹ã€æˆ–è¯´ã€Œç¿»è¯‘ã€ç¿»è¯‘å½“å‰ç”»é¢ï¼‰")
                                    elif action and action in ("translate", "pronounce", "examples"):
                                        content_for_cmd = state.get_content_for_command()
                                        state.set_pending_user_command(action, content_for_cmd)
                                    elif action == "send_ocr_result":
                                        content_c = state.get_content_for_command()
                                        if content_c:
                                            state.append_chat("assistant", "å½“å‰è¯†åˆ«åˆ°çš„æ–‡å­—ï¼š\n" + content_c)
                                        else:
                                            state.append_chat("assistant", "ï¼ˆå½“å‰ç”»é¢æš‚æ— è¯†åˆ«åˆ°æ–‡å­—ï¼Œè¯·å¯¹å‡†æ–‡å­—åå†è¯•ï¼‰")
                            except Exception as e:
                                state.append_chat("assistant", f"(åŠ©æ‰‹å‡ºé”™: {str(e)[:50]})")
                        threading.Thread(target=_run_chat_assistant, daemon=True).start()

        # è‹¥æœ‰æœªå®Œæˆçš„ LLM è¯·æ±‚ï¼Œå…ˆçœ‹æ˜¯å¦å·²å®Œæˆï¼ˆä¸é˜»å¡ï¼‰
        if pending_llm is not None:
            future_llm, pending_stable, pending_conf, pending_ocr_ms, pending_display, pending_err = pending_llm
            if future_llm.done():
                try:
                    corrected, llm_ms, llm_ok, llm_err = future_llm.result(timeout=0)
                except Exception as e:
                    corrected, llm_ms, llm_ok, llm_err = pending_stable, 0.0, False, str(e)
                if llm_ok:
                    circuit_breaker.record_success()
                    last_sent_text = pending_stable
                    last_corrected = corrected
                    if cache is not None and pending_stable.strip():
                        try:
                            cache.put(
                                text=pending_stable,
                                lang_hint=last_llm_lang_hint,
                                corrected=corrected,
                                confidence=None,
                                language_hint=None,
                                llm_ms=llm_ms,
                            )
                        except Exception:
                            pass
                else:
                    circuit_breaker.record_failure()
                combined_err = " ".join(filter(None, [pending_err, llm_err])) or None
                if metrics is not None:
                    try:
                        metrics.set_ocr_llm_ms(pending_ocr_ms, llm_ms)
                    except Exception:
                        pass
                _run_vision_and_cross_validate(state, corrected)
                state.set_latest_result(
                    raw_ocr=pending_display,
                    corrected=corrected,
                    confidence=pending_conf,
                    ocr_time_ms=pending_ocr_ms,
                    llm_time_ms=llm_ms,
                    ocr_ok=True,
                    llm_ok=llm_ok,
                    error_msg=combined_err,
                    debounced_ocr=pending_stable,
                )
                if config.LOG_TO_FILE and pending_stable.strip():
                    log_result(pending_stable, corrected, pending_conf, pending_ocr_ms, llm_ms)
                if getattr(config, "ENABLE_TTS", False) and corrected.strip():
                    try:
                        tts_speak(corrected)
                    except Exception:
                        pass
                pending_llm = None

        try:
            frame = state.get_frame_for_ocr(
                config.FRAME_SKIP,
                fusion_frames=getattr(config, "OCR_FUSION_FRAMES", 0),
                motion_stable_enabled=getattr(config, "OCR_MOTION_STABLE_ENABLED", False),
                motion_threshold=float(getattr(config, "OCR_MOTION_STABLE_THRESHOLD", 20.0)),
            )
        except Exception as e:
            log(f"get_frame_for_ocr å¼‚å¸¸: {e}", level="ERROR")
            time.sleep(0.2)
            continue
        if frame is None:
            time.sleep(0.05)
            continue

        # å­˜å½“å‰å¸§ä¾›è§†è§‰ LLM ä¸ OCR äº¤å‰éªŒè¯ç”¨
        state.set_last_ocr_frame(frame)

        # OCR åœ¨æ± ä¸­æ‰§è¡Œï¼Œå¸¦è¶…æ—¶
        try:
            future_ocr = executor.submit(_run_ocr_safe, frame)
            raw_text, conf, ocr_ms, ocr_ok, err_msg = future_ocr.result(
                timeout=config.OCR_FUTURE_TIMEOUT_SEC
            )
        except (FuturesTimeoutError, Exception) as e:
            raw_text, conf, ocr_ms = "", 0.0, 0.0
            ocr_ok = False
            err_msg = str(e)
            log(f"OCR å¼‚å¸¸/è¶…æ—¶: {e}", level="ERROR")
            save_debug_frame(frame, "ocr_error")

        # å»æŠ–åŠ¨ï¼šç”¨æœ€è¿‘ N æ¬¡ä¸­å¤šæ•°/ç¨³å®šç»“æœä½œä¸ºæ˜¾ç¤ºä¸ LLM è¾“å…¥
        debouncer.add(raw_text if ocr_ok else "")
        stable_text = debouncer.get_stable()
        is_stable = debouncer.is_stable()
        # è½¯ç¨³å®šï¼šå½“å‰å¸§ä¸ç¨³å®šæ–‡æœ¬ç›¸ä¼¼åº¦é«˜ï¼Œä¹Ÿè§†ä¸ºå·²â€œè¯†åˆ«å®Œæˆâ€ï¼Œè§¦å‘ LLM
        soft_stable = is_stable
        if getattr(config, "OCR_SOFT_STABLE_ENABLED", True) and stable_text and raw_text:
            from agents.debounce import text_similarity

            sim = text_similarity(stable_text, raw_text)
            if sim >= getattr(config, "OCR_SOFT_STABLE_SIMILARITY", 0.85):
                soft_stable = True

        # åŸå§‹ OCR ä¸€æœ‰ç»“æœå°±æ˜¾ç¤ºï¼šraw_ocr ç”¨å½“å‰å¸§è¯†åˆ«ç»“æœ raw_textï¼Œä¸ç­‰åˆ°å»æŠ–
        display_raw = raw_text if ocr_ok else (stable_text or "(OCRå¤±è´¥)")

        if not ocr_ok:
            # OCR å¤±è´¥æ—¶æŠŠå…·ä½“é”™è¯¯å†™å…¥æ—¥å¿—ï¼ˆå¼•æ“å†…éƒ¨å¼‚å¸¸ä¸ä¼šæŠ›åˆ° result()ï¼Œåªä¼šåœ¨ error_msg é‡Œï¼‰
            if err_msg:
                log(f"OCR å¤±è´¥: {err_msg}", level="ERROR")
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=stable_text or "(OCRå¤±è´¥)",
                confidence=0.0,
                ocr_time_ms=ocr_ms,
                llm_time_ms=0.0,
                ocr_ok=False,
                llm_ok=True,
                error_msg=err_msg,
                debounced_ocr=stable_text or "",
            )
            if config.LOG_TO_FILE and (raw_text or err_msg):
                log_result(raw_text or "", stable_text or "", 0.0, ocr_ms, 0.0)
            time.sleep(0.05)
            continue

        # æ— æœ‰æ•ˆæ–‡æœ¬æˆ–æ–‡æœ¬å°šæœªç¨³å®šï¼šåªæ›´æ–°æ˜¾ç¤ºï¼ˆåŸå§‹OCRç”¨å½“å‰å¸§ç»“æœï¼‰ï¼Œä¸è¯·æ±‚ LLM
        if not (stable_text and stable_text.strip()) or not soft_stable:
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=raw_text,
                confidence=conf,
                ocr_time_ms=ocr_ms,
                llm_time_ms=0.0,
                ocr_ok=True,
                llm_ok=True,
                error_msg=None,
                debounced_ocr=stable_text,
            )
            time.sleep(0.05)
            continue

        # Agent Eï¼šç¼“å­˜å‘½ä¸­åˆ™ç›´æ¥ä½¿ç”¨ï¼Œä¸é‡å¤è¯·æ±‚ LLM
        cache_entry = cache.get(stable_text, last_llm_lang_hint) if cache is not None else None
        if cache_entry is not None:
            corrected = cache_entry["corrected"]
            llm_ms = float(cache_entry.get("llm_ms", 0.0))
            combined_err = err_msg
            if metrics is not None:
                try:
                    metrics.set_ocr_llm_ms(ocr_ms, llm_ms)
                except Exception:
                    pass
            _run_vision_and_cross_validate(state, corrected)
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=corrected,
                confidence=conf,
                ocr_time_ms=ocr_ms,
                llm_time_ms=llm_ms,
                ocr_ok=True,
                llm_ok=True,
                error_msg=combined_err,
                debounced_ocr=stable_text,
            )
            if config.LOG_TO_FILE and stable_text.strip():
                log_result(stable_text, corrected, conf, ocr_ms, llm_ms)
            if getattr(config, "ENABLE_TTS", False) and corrected.strip():
                try:
                    tts_speak(corrected)
                except Exception:
                    pass
            time.sleep(0.05)
            continue

        # æ–‡å­—ä¸ä¸Šæ¬¡å‘ç»™ LLM çš„å®Œå…¨ç›¸åŒï¼šä¸é‡å¤å‘ï¼Œç”¨ä¸Šæ¬¡çº é”™ç»“æœ
        if last_sent_text is not None and last_corrected is not None and stable_text == last_sent_text:
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=last_corrected,
                confidence=conf,
                ocr_time_ms=ocr_ms,
                llm_time_ms=0.0,
                ocr_ok=True,
                llm_ok=True,
                error_msg=None,
                debounced_ocr=stable_text,
            )
            time.sleep(0.05)
            continue

        # ç†”æ–­æ‰“å¼€åˆ™ä¸å†è¯·æ±‚ LLMï¼Œç›´æ¥è¿”å›åŸæ–‡
        if circuit_breaker.is_open():
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=stable_text,
                confidence=conf,
                ocr_time_ms=ocr_ms,
                llm_time_ms=0.0,
                ocr_ok=True,
                llm_ok=False,
                error_msg="LLMç†”æ–­ä¸­(é™çº§è¿”å›åŸæ–‡)",
                debounced_ocr=stable_text,
            )
            time.sleep(0.05)
            continue

        # Agent Eï¼šèŠ‚æµï¼Œè¿‡äºé¢‘ç¹åˆ™æš‚ä¸è¯·æ±‚ LLMï¼Œåªæ˜¾ç¤ºåŸæ–‡
        if throttler is not None and not throttler.can_call():
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=stable_text,
                confidence=conf,
                ocr_time_ms=ocr_ms,
                llm_time_ms=0.0,
                ocr_ok=True,
                llm_ok=True,
                error_msg=None,
                debounced_ocr=stable_text,
            )
            time.sleep(0.05)
            continue

        # å·²æœ‰ LLM åœ¨é€”åˆ™åªæ›´æ–°ç”»é¢ï¼ˆåŸå§‹/å»æŠ–ï¼‰ï¼Œä¸é‡å¤æäº¤
        if pending_llm is not None:
            state.set_latest_result(
                raw_ocr=display_raw,
                corrected=stable_text,
                confidence=conf,
                ocr_time_ms=ocr_ms,
                llm_time_ms=0.0,
                ocr_ok=True,
                llm_ok=True,
                error_msg=None,
                debounced_ocr=stable_text,
            )
            time.sleep(0.05)
            continue

        # æäº¤ LLM å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ï¼›ç»“æœåœ¨ä¸‹ä¸€è½®å¾ªç¯ä¸­åˆå¹¶
        log(f"è°ƒç”¨æœ¬åœ° LLM çº é”™: ã€Œ{(stable_text[:60] + '...') if len(stable_text) > 60 else stable_text}ã€", level="INFO")
        future_llm = executor.submit(_run_llm_safe, stable_text)
        last_sent_text = stable_text
        pending_llm = (future_llm, stable_text, conf, ocr_ms, display_raw, err_msg)
        state.set_latest_result(
            raw_ocr=display_raw,
            corrected=stable_text,
            confidence=conf,
            ocr_time_ms=ocr_ms,
            llm_time_ms=0.0,
            ocr_ok=True,
            llm_ok=True,
            error_msg=err_msg,
            debounced_ocr=stable_text,
        )
        time.sleep(0.05)


def start_worker(state: SharedState, metrics: Optional["Metrics"] = None) -> threading.Thread:
    """å¯åŠ¨ç®¡é“çº¿ç¨‹ä¸çº¿ç¨‹æ± ï¼›ä¸»çº¿ç¨‹ä»…éœ€è°ƒç”¨ start_worker ä¸€æ¬¡ï¼Œæ°¸ä¸ç­‰å¾…ã€‚

    Agent Dï¼šå¯ä¼ å…¥ metrics æ‰“æŒ‡æ ‡ï¼›
    Agent Eï¼šå†…éƒ¨åˆ›å»º LLM ç¼“å­˜ä¸èŠ‚æµå™¨ï¼Œæå‡æ€§èƒ½ä¸ä½“éªŒã€‚
    """
    executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="ocr_llm")
    circuit_breaker = _CircuitBreaker(
        failure_threshold=config.LLM_CIRCUIT_BREAKER_FAILURES,
        cooldown_sec=config.LLM_CIRCUIT_BREAKER_COOLDOWN_SEC,
    )
    debouncer = OCRDebouncer(
        history_len=getattr(config, "OCR_DEBOUNCE_HISTORY_LEN", 6),
        min_votes=getattr(config, "OCR_DEBOUNCE_MIN_VOTES", 4),
        similarity_vote=getattr(config, "OCR_DEBOUNCE_SIMILARITY_VOTE", 0.88),
    )
    cache = LLMCache(
        max_size=getattr(config, "LLM_CACHE_MAX_SIZE", 200),
        ttl_sec=getattr(config, "LLM_CACHE_TTL_SEC", 600),
    )
    throttler = LLMThrottler(
        min_interval_ms=getattr(config, "LLM_MIN_INTERVAL_MS", 1000),
    )
    # å¯åŠ¨å‰ç”¨ç©ºç™½å›¾è§¦å‘ä¸€æ¬¡ OCR åˆå§‹åŒ–ï¼Œç¯å¢ƒå¼‚å¸¸æ—¶åœ¨å¯åŠ¨é˜¶æ®µæŠ¥ä¸€æ¬¡è€Œéæ¯å¸§åˆ·å±
    try:
        import numpy as np
        _dummy = np.zeros((64, 256, 3), dtype=np.uint8)
        _ = run_ocr(_dummy)
    except Exception:
        pass
    daemon = threading.Thread(
        target=_pipeline_loop,
        args=(state, executor, circuit_breaker, debouncer, metrics, cache, throttler),
        daemon=True,
        name="pipeline",
    )
    daemon.start()
    return daemon
