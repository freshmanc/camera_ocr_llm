# -*- coding: utf-8 -*-
"""
ç™½åº•é»‘å­—å¯äº¤äº’å¯¹è¯çª—å£ï¼šæ–‡å­—è¾“å…¥ã€å‘é€ã€å°éº¦å…‹é£ç‚¹å‡»è¯­éŸ³ã€‚ä¸ SharedState åŒæ­¥ï¼Œæ”¯æŒæœ¬åœ° LLM åŠ¨ä½œï¼ˆæœ—è¯»/ç¿»è¯‘/è¯»éŸ³/ä¾‹å¥ï¼‰ã€‚
"""
from __future__ import annotations

import os
import threading
import tkinter as tk
from tkinter import font as tkfont
from tkinter import scrolledtext
from typing import TYPE_CHECKING, Callable, Optional

if TYPE_CHECKING:
    from shared_state import SharedState


def _wrap_text(text: str, width_chars: int = 36) -> list[str]:
    out = []
    for line in text.split("\n"):
        s = line.strip()
        while len(s) > width_chars:
            out.append(s[:width_chars])
            s = s[width_chars:]
        if s:
            out.append(s)
    return out or [""]


class ChatWindow:
    """ç™½åº•é»‘å­—å¯¹è¯çª—å£ï¼šèŠå¤©åŒº + è¾“å…¥æ¡† + å‘é€ + éº¦å…‹é£æŒ‰é’®ã€‚ç”±ä¸»å¾ªç¯è°ƒç”¨ update_from_state() åˆ·æ–°ã€‚"""

    def __init__(self, state: "SharedState", title: str = "è¯­éŸ³åŠ©æ‰‹"):
        self.state = state
        self.title = title
        self._root: Optional[tk.Tk] = None
        self._chat_text: Optional[tk.Text] = None
        self._entry: Optional[tk.Entry] = None
        self._last_history_len = -1
        self._get_content_for_command: Optional[Callable[[], str]] = None
        self._stop_voice = threading.Event()
        self._voice_recording = False
        self._play_tag_to_path: dict = {}
        self._last_history_sig: Optional[str] = None  # ä»…å½“å¯¹è¯å˜åŒ–æ—¶é‡ç»˜ï¼Œé¿å…æ¯å¸§åˆ·æ–°

    def set_content_for_command_callback(self, fn: Callable[[], str]) -> None:
        """å¯é€‰ï¼šç”¨äºè¯­éŸ³æŒ‡ä»¤å–å½“å‰è¯†åˆ«å†…å®¹ï¼ˆä¸ worker ä¸€è‡´ï¼‰ã€‚"""
        self._get_content_for_command = fn

    def build(self) -> tk.Tk:
        self._root = tk.Tk()
        self._root.title(self.title)
        self._root.configure(bg="#ffffff")
        self._root.geometry("500x480+80+80")
        self._root.minsize(380, 400)

        # å…ˆæ”¾åº•éƒ¨æ ï¼Œä¿è¯è¾“å…¥æ¡†å’Œã€Œè¯­éŸ³ã€å§‹ç»ˆåœ¨çª—å£åº•éƒ¨å¯è§
        bottom = tk.Frame(self._root, bg="#ffffff", height=56)
        bottom.pack(side=tk.BOTTOM, fill=tk.X, padx=8, pady=(0, 8))
        bottom.pack_propagate(False)

        # èŠå¤©åŒºåŸŸåœ¨ä¸Šæ–¹ï¼Œå¡«å……å‰©ä½™ç©ºé—´
        chat_frame = tk.Frame(self._root, bg="#ffffff")
        chat_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True, padx=8, pady=8)
        font_chat = tkfont.Font(family="Microsoft YaHei UI" if tkfont.nametofont("TkDefaultFont").actual() else "TkDefaultFont", size=11)
        self._chat_text = scrolledtext.ScrolledText(
            chat_frame,
            wrap=tk.WORD,
            font=font_chat,
            bg="#ffffff",
            fg="#000000",
            insertbackground="#000000",
            state=tk.DISABLED,
            padx=6,
            pady=6,
        )
        self._chat_text.pack(fill=tk.BOTH, expand=True)
        self._chat_text.bind("<Key>", lambda e: "break")  # ç¦æ­¢åœ¨èŠå¤©åŒºæ‰“å­—ï¼Œä½†ä¿æŒ NORMAL ä»¥ä¾¿ç‚¹å‡»ã€Œæ’­æ”¾ã€
        self._entry = tk.Entry(
            bottom,
            font=("Microsoft YaHei UI", 11),
            bg="#ffffff",
            fg="#000000",
            insertbackground="#000000",
            relief=tk.SOLID,
            bd=2,
            highlightthickness=1,
            highlightcolor="#888888",
        )
        self._entry.pack(side=tk.LEFT, fill=tk.X, expand=True, ipady=6, padx=(0, 6))
        self._entry.bind("<Return>", lambda e: self._on_send())

        send_btn = tk.Button(
            bottom,
            text="å‘é€",
            font=("Microsoft YaHei UI", 10),
            bg="#e0e0e0",
            fg="#000000",
            activebackground="#d0d0d0",
            relief=tk.RAISED,
            bd=1,
            padx=12,
            pady=6,
            cursor="hand2",
            command=self._on_send,
        )
        send_btn.pack(side=tk.LEFT, padx=(0, 6))

        # å°éº¦å…‹é£ï¼šæŒ‰ä½è¯´è¯ã€æ¾å¼€ç»“æŸå¹¶è¯†åˆ«
        mic_btn = tk.Button(
            bottom,
            text="è¯­éŸ³",
            font=("Microsoft YaHei UI", 10),
            bg="#dae8fc",
            fg="#000000",
            activebackground="#b8d4f0",
            relief=tk.RAISED,
            bd=1,
            padx=10,
            pady=6,
            cursor="hand2",
        )
        mic_btn.bind("<ButtonPress-1>", lambda e: self._on_mic_press())
        mic_btn.bind("<ButtonRelease-1>", lambda e: self._on_mic_release())
        mic_btn.pack(side=tk.LEFT)

        # çª—å£ç½®å‰å¹¶è®©è¾“å…¥æ¡†è·å¾—ç„¦ç‚¹ï¼Œä¾¿äºç›´æ¥æ‰“å­—
        self._root.lift()
        self._root.attributes("-topmost", True)
        self._root.after(200, self._focus_entry)
        self._root.after(500, lambda: self._root.attributes("-topmost", False))

        return self._root

    def _focus_entry(self) -> None:
        if self._entry and self._root:
            try:
                self._entry.focus_set()
            except tk.TclError:
                pass

    def _on_send(self) -> None:
        if not self._entry:
            return
        msg = (self._entry.get() or "").strip()
        self._entry.delete(0, tk.END)
        if not msg:
            return
        self.state.append_chat("user", msg)
        self.state.append_chat("assistant", "å·²æ”¶åˆ°ï¼Œæ­£åœ¨å¤„ç†â€¦")
        self.state.set_pending_chat(msg)
        self._last_history_len = -1
        self._entry.focus_set()

    def _on_mic_press(self) -> None:
        if self._voice_recording:
            return
        self._voice_recording = True
        self._stop_voice.clear()
        self.state.append_chat("assistant", "æ­£åœ¨å¬â€¦ï¼ˆæ¾å¼€ç»“æŸï¼‰")
        self._last_history_len = -1
        threading.Thread(target=self._record_until_release, daemon=True).start()

    def _on_mic_release(self) -> None:
        self._stop_voice.set()

    def _record_until_release(self) -> None:
        """æŒ‰ä½æœŸé—´å½•éŸ³ï¼Œæ¾æ‰‹ååœæ­¢å¹¶è¯†åˆ«ã€‚"""
        try:
            import speech_recognition as sr
            import pyaudio
        except ImportError:
            self.state.append_chat("assistant", "è¯­éŸ³è¾“å…¥éœ€è¦å®‰è£…: pip install SpeechRecognition pyaudio")
            self._voice_recording = False
            self._last_history_len = -1
            return
        try:
            pa = pyaudio.PyAudio()
            rate, chunk_frames = 16000, 1600  # 0.1 ç§’ä¸€å—
            stream = pa.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=rate,
                input=True,
                frames_per_buffer=chunk_frames,
            )
            chunks = []
            max_sec = 30
            while not self._stop_voice.is_set() and (len(chunks) * 0.1 < max_sec):
                try:
                    data = stream.read(chunk_frames, exception_on_overflow=False)
                    chunks.append(data)
                except Exception:
                    break
            stream.stop_stream()
            stream.close()
            pa.terminate()

            if len(chunks) < 5:
                self.state.append_chat("assistant", "ï¼ˆå½•éŸ³å¤ªçŸ­ï¼Œè¯·æŒ‰ä½ã€Œè¯­éŸ³ã€è¯´è¯åæ¾å¼€ï¼‰")
            else:
                audio_bytes = b"".join(chunks)
                # å¯é€‰é™å™ªï¼ˆéœ€å®‰è£… noisereduceï¼‰
                try:
                    import config as _voice_cfg
                    if getattr(_voice_cfg, "VOICE_REDUCE_NOISE", False):
                        import numpy as np
                        import noisereduce as nr
                        arr = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                        arr = nr.reduce_noise(y=arr, sr=rate, prop_decrease=0.8)
                        audio_bytes = (np.clip(arr, -1.0, 1.0) * 32767.0).astype(np.int16).tobytes()
                except ImportError:
                    pass
                except Exception:
                    pass
                try:
                    import config as _voice_cfg
                    engine = (getattr(_voice_cfg, "VOICE_RECOGNITION_ENGINE", "google") or "google").strip().lower()
                except Exception:
                    engine = "google"
                r = sr.Recognizer()
                audio = sr.AudioData(audio_bytes, rate, 2)
                text = None
                if engine == "whisper":
                    try:
                        text = r.recognize_whisper(audio, language="zh", model="base")
                    except AttributeError:
                        text = r.recognize_google(audio, language="zh-CN")
                    except Exception as e_whisper:
                        # Windows ä¸Š Whisper å¸¸å›  WinError 127ï¼ˆDLL/ä¾èµ–ç¼ºå¤±æˆ–å†²çªï¼‰å¤±è´¥ï¼Œå›é€€åˆ°è°·æ­Œ
                        try:
                            import sys
                            print(f"[è¯­éŸ³] Whisper å¤±è´¥ï¼Œå›é€€è°·æ­Œ: {e_whisper}", file=sys.stderr)
                        except Exception:
                            pass
                        try:
                            text = r.recognize_google(audio, language="zh-CN")
                            self.state.append_chat("assistant", "ï¼ˆWhisper ä¸å¯ç”¨ï¼Œå·²ç”¨è°·æ­Œè¯†åˆ«ï¼›éœ€è”ç½‘ï¼‰")
                        except Exception:
                            raise
                if text is None:
                    text = r.recognize_google(audio, language="zh-CN")
                if text and text.strip():
                    self.state.append_chat("user", text.strip())
                    self.state.append_chat("assistant", "å·²è¯†åˆ«ï¼Œæ­£åœ¨å¤„ç†â€¦")
                    self.state.set_pending_chat(text.strip())
                else:
                    self.state.append_chat("assistant", "ï¼ˆæœªè¯†åˆ«åˆ°å†…å®¹ï¼Œè¯·é‡è¯•ï¼‰")
        except Exception as e:
            self.state.append_chat("assistant", f"ï¼ˆè¯­éŸ³è¯†åˆ«å¼‚å¸¸: {str(e)[:40]}ï¼‰")
        finally:
            self._voice_recording = False
        self._last_history_len = -1

    def _play_audio_in_app(self, path: str) -> None:
        """åº”ç”¨å†…æ’­æ”¾éŸ³é¢‘ï¼Œä¸å¼¹çª—ã€‚ä¼˜å…ˆ pygameï¼Œå…¶æ¬¡ playsoundï¼Œæœ€åæ‰ç”¨ç³»ç»Ÿæ’­æ”¾å™¨ã€‚"""
        if not path or not os.path.isfile(path):
            return
        path = os.path.abspath(path)

        def _do() -> None:
            import time as _time
            # 1) ä¼˜å…ˆ pygameï¼šWindows ä¸‹åº”ç”¨å†…æ’­ MP3 é€šå¸¸å¯ç”¨
            try:
                import pygame
                if not pygame.mixer.get_init():
                    pygame.mixer.init(frequency=44100, size=-16, channels=2)
                pygame.mixer.music.load(path)
                pygame.mixer.music.play()
                while pygame.mixer.music.get_busy():
                    _time.sleep(0.05)
                return
            except ImportError:
                pass
            except Exception as e:
                _log_play_error("pygame", path, e)
            # 2) å…¶æ¬¡ playsound
            try:
                import playsound
                playsound.playsound(path, block=True)
                return
            except ImportError:
                pass
            except Exception as e:
                _log_play_error("playsound", path, e)
            # 3) æœ€åæ‰ç”¨ç³»ç»Ÿæ’­æ”¾å™¨ï¼ˆä¼šå¼¹çª—ï¼‰
            if os.name == "nt":
                try:
                    os.startfile(path)
                except Exception as e2:
                    _log_play_error("startfile", path, e2)

        def _log_play_error(method: str, p: str, err: Exception) -> None:
            try:
                import sys
                print(f"[æ’­æ”¾] {method} å¤±è´¥: {p!r} -> {err}", file=sys.stderr)
            except Exception:
                pass

        threading.Thread(target=_do, daemon=True).start()

    def update_from_state(self) -> None:
        """ä¸»å¾ªç¯æ¯å¸§è°ƒç”¨ï¼šä»…å½“å¯¹è¯å˜åŒ–æ—¶é‡ç»˜ï¼Œé¿å…ä¸åœåˆ·æ–°ï¼›å¸¦éŸ³é¢‘çš„æ¶ˆæ¯æ˜¾ç¤ºã€ŒğŸ”Š æ’­æ”¾ã€å¯ç‚¹å‡»ã€‚"""
        if not self._root or not self._chat_text:
            return
        try:
            import time as time_mod
            history = self.state.get_chat_history()
            streaming = self.state.get_streaming_content()
            sig = str(len(history)) + (str(history[-1]) if history else "")
            if streaming is not None:
                sig += "_stream_%d" % len(streaming)  # æµå¼æ—¶éšå†…å®¹å¢é•¿è§¦å‘é‡ç»˜ï¼ŒåŠæ—¶æ˜¾ç¤º LLM è¾“å‡º
            if sig == self._last_history_sig:
                return
            self._last_history_sig = sig
            self._last_history_len = len(history)
            self._play_tag_to_path.clear()
            self._chat_text.configure(state=tk.NORMAL)
            self._chat_text.delete("1.0", tk.END)
            try:
                import config
                hint = getattr(config, "DIALOG_FEATURE_PROMPT", "")
            except Exception:
                hint = "åœ¨ä¸‹æ–¹è¾“å…¥æ¡†æ‰“å­—ï¼Œç‚¹ã€Œå‘é€ã€æˆ–å›è½¦å‘é€ï¼›æŒ‰ä½ã€Œè¯­éŸ³ã€è¯´è¯ï¼Œæ¾å¼€ç»“æŸã€‚"
            if not hint:
                hint = "åœ¨ä¸‹æ–¹è¾“å…¥æ¡†æ‰“å­—ï¼Œç‚¹ã€Œå‘é€ã€æˆ–å›è½¦å‘é€ï¼›æŒ‰ä½ã€Œè¯­éŸ³ã€è¯´è¯ï¼Œæ¾å¼€ç»“æŸã€‚"
            self._chat_text.insert(tk.END, hint.strip() + "\n\n")
            if history:
                self._chat_text.insert(tk.END, "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¯¹è¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n")
            play_idx = 0
            for item in history:
                role = item[0]
                text = item[1] if len(item) > 1 else ""
                ts = item[2] if len(item) > 2 else None
                audio_path = (item[3] if len(item) > 3 else "") or ""
                tstr = time_mod.strftime("%H:%M:%S", time_mod.localtime(ts)) if ts else ""
                prefix = ("æˆ‘ " + tstr + "  ") if role == "user" else ("åŠ©æ‰‹ " + tstr + "  ")
                lines = _wrap_text(text or "")
                for i, line in enumerate(lines):
                    self._chat_text.insert(tk.END, (prefix if i == 0 else "    ") + line + "\n")
                if audio_path and role == "assistant" and os.path.isfile(audio_path):
                    play_idx += 1
                    path_for_btn = audio_path
                    btn = tk.Button(
                        self._chat_text,
                        text=" ğŸ”Š æ’­æ”¾ ",
                        font=("Microsoft YaHei UI", 10, "bold"),
                        fg="#fff",
                        bg="#0066cc",
                        activeforeground="#fff",
                        activebackground="#0052a3",
                        relief=tk.FLAT,
                        padx=8,
                        pady=2,
                        cursor="hand2",
                        command=(lambda p=path_for_btn: self._play_audio_in_app(p)),
                    )
                    self._chat_text.insert(tk.END, " ")
                    self._chat_text.window_create(tk.END, window=btn)
                    self._chat_text.insert(tk.END, "\n")
                else:
                    self._chat_text.insert(tk.END, "\n")
            self._chat_text.see(tk.END)
            # è‡ªåŠ¨æ’­æ”¾ï¼šè‹¥æœ¬æ¡æ˜¯åˆšè¿½åŠ çš„å¸¦éŸ³é¢‘æ¶ˆæ¯ï¼Œç«‹å³æ’­æ”¾
            pending = self.state.get_and_clear_pending_play_audio()
            if pending and os.path.isfile(pending):
                self._play_audio_in_app(pending)
            # ä¿æŒ NORMAL ä»¥ä¾¿ç‚¹å‡»ã€Œæ’­æ”¾ã€èƒ½è§¦å‘
        except Exception:
            pass

    def update(self) -> None:
        """å¤„ç† tk äº‹ä»¶ï¼ˆä¸»å¾ªç¯ä¸­è°ƒç”¨ï¼‰ï¼Œå¤šå¤„ç†å‡ æ¬¡ä¿è¯æ‰“å­—å’Œç‚¹å‡»èƒ½å“åº”ã€‚"""
        if self._root:
            try:
                self._root.update_idletasks()
                for _ in range(3):
                    self._root.update()
            except tk.TclError:
                pass

    def destroy(self) -> None:
        """å…³é—­çª—å£ã€‚"""
        if self._root:
            try:
                self._root.destroy()
            except tk.TclError:
                pass
            self._root = None
